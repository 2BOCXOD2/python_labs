# **–õ–∞–±–æ—Ä–∞—Ç–æ—Ä–Ω–∞—è —Ä–∞–±–æ—Ç–∞ ‚Ññ3**
## **–ó–∞–¥–∞–Ω–∏–µ A**
### –ö–æ–¥ –∑–∞–¥–∞–Ω–∏—è ‚Ññ1
```
def normalize(text: str, *, casefold: bool = True, yo2e: bool = True):
    if type(text) == str:
        if casefold == True: # –ï—Å–ª–∏ –≤–∫–ª—é—á–µ–Ω–æ, –¥–µ–ª–∞–µ—Ç –≤—Å–µ –±—É–∫–≤—ã —Å—Ç—Ä–æ—á–Ω—ã–º–∏
            text = text.casefold()
        if yo2e == True: # –ï—Å–ª–∏ –≤–∫–ª—é—á–µ–Ω–æ, –¥–µ–ª–∞–µ—Ç –≤—Å–µ –Å/—ë –±—É–∫–≤–∞–º–∏ –ï/–µ
            text = text.replace("—ë", "–µ")
            text = text.replace("–Å", "–ï")
        text = text.split() # –£–±–∏—Ä–∞–µ—Ç –ª–∏—à–Ω–∏–µ –ø—Ä–æ–±–µ–ª—ã
        new_text = ""
        lenn = len(text)
        for i in range(lenn): # –ü—Ä–µ–≤—Ä–∞—â–∞–µ—Ç —Å–ø–∏—Å–æ–∫ –Ω–∞–∑–∞–¥ –≤ —Å—Ç—Ä–æ–∫—É
            if i < lenn - 1:
                new_text = f"{new_text + text[i]} "
            else:
                new_text = f"{new_text + text[i]}"
        new_text = new_text.replace("\n", '') # –£–¥–∞–ª—è–µ—Ç –≤—Å–µ –ª–∏—à–Ω–∏–µ —Å–∏–º–≤–æ–ª—ã
        new_text = new_text.replace("\r", '')
        new_text = new_text.replace("\t", '')
        return new_text
    else:
        raise TypeError

textt = "   \n–ï–µ–Å—ë   \r–ê–ë–≤–≥–î   \t12(%‚Ññ?*)?;         "
print(normalize(textt, casefold=True, yo2e=True))
```
–°–∫—Ä–∏–Ω—à–æ—Ç –∑–∞–¥–∞–Ω–∏—è ‚Ññ1
![01](https://github.com/2BOCXOD2/python_labs/blob/main/img/lab03/1.1.PNG)
### –ö–æ–¥ –∑–∞–¥–∞–Ω–∏—è ‚Ññ2
```
def tokenize(text: str):
    if type(text) == str:
        alf = ",.!_;:?üòÄ" # –°–∏–º–≤–æ–ª—ã-–ø—Ä–æ–±–µ–ª—ã
        text = text.split()
        lenn = len(text)
        new_text = ''
        for i in range(lenn): # –£–¥–∞–ª–∏–ª–∏ –ø—Ä–æ–±–µ–ª—ã –∏ –ø–µ—Ä–µ–≤–æ–¥–∏–º –≤ —Ç–∏–ø —Å—Ç—Ä–æ–∫–∏
            if i < lenn - 1:
                new_text = f"{new_text + text[i]} "
            else:
                new_text = f"{new_text + text[i]}"
        for a in alf: # –£–¥–∞–ª—è–µ–º —Å–∏–º–≤–æ–ª—ã-–ø—Ä–æ–±–µ–ª—ã –∏ –ø–µ—Ä–µ–≤–æ–¥–∏–º –≤ —Ç–∏–ø —Å—Ç—Ä–æ–∫–∏
            text = new_text
            text = text.split(a)
            lenn = len(text)
            new_text = ""
            for j in range(lenn):
                if j < lenn - 1:
                    new_text = f"{new_text + text[j]} "
                else:
                    new_text = f"{new_text + text[j]}"
        new_text = new_text.split()
        return new_text
    else:
        raise TypeError
texxt = "emoji üòÄ –Ω–µ —Å–ª–æ–≤–æ"
print(tokenize(texxt))
```
–°–∫—Ä–∏–Ω—à–æ—Ç –∑–∞–¥–∞–Ω–∏—è ‚Ññ2
![02](https://github.com/2BOCXOD2/python_labs/blob/main/img/lab03/1.2.PNG)
### –ö–æ–¥ –∑–∞–¥–∞–Ω–∏–π ‚Ññ3 –∏ ‚Ññ4
```
def count_freq(dannye):
    new_dannye = []
    for i in dannye:
        if i in new_dannye:
            pass
        else:
            new_dannye.append(i)
    slovar = {}
    for z in new_dannye:
        col = dannye.count(z) # –ö–æ–ª–∏—á–µ—Å—Ç–≤–æ –≤—Ö–æ–∂–¥–µ–Ω–∏–π
        slovar[z] = col
    return slovar
def top_n(dictt, n_top):
    a = []
    for key, value in dictt.items():
        a.append((key, value))
    otv = a.sort() # –°–æ—Ä—Ç–∏—Ä–æ–≤–∫–∞ –ø–æ –∞–ª—Ñ–∞–≤–∏—Ç—É
    otv = sorted(a, key = lambda x: (x[1]), reverse=True) # –°–æ—Ä—Ç–∏—Ä–æ–≤–∫–∞ –ø–æ —á–∞—Å—Ç–æ—Ç–µ
    otv_1 = []
    if n_top > len(dictt): # –ü—Ä–æ–≤–µ—Ä–∫–∞ –¥–ª–∏–Ω—ã
        for i in range(len(dictt)): # –§–æ—Ä–º–∏—Ä–æ–≤–∞–Ω–∏–µ —Ç–æ–ø–∞
            otv_1.append(otv[i])
    else:
        for i in range(n_top): # –§–æ—Ä–º–∏—Ä–æ–≤–∞–Ω–∏–µ —Ç–æ–ø–∞
            otv_1.append(otv[i])
    return otv_1
spisok = ["bb","aa","bb","aa","cc"]
n = 2
print(count_freq(spisok))
print(top_n(count_freq(spisok), n))
```
–°–∫—Ä–∏–Ω—à–æ—Ç –∑–∞–¥–∞–Ω–∏–π ‚Ññ3 –∏ ‚Ññ4
![03](https://github.com/2BOCXOD2/python_labs/blob/main/img/lab03/1.3%2C4.PNG)
## **–ó–∞–¥–∞–Ω–∏–µ B**
### –ö–æ–¥ –∑–∞–¥–∞–Ω–∏—è B
```
import sys
import os
sys.path.insert(0, os.path.join(sys.path[0], '../lib')) # –î–æ–±–∞–≤–∏–ª–∏ –ø—É—Ç—å –≤ –ø–∞–ø–∫—É —Å —Ñ—É–Ω–∫—Ü–∏—è–º–∏
import text # normalize, tokenize, count_freq, top_n

s = "–ü—Ä–∏–≤–µ—Ç, –º–∏—Ä! –ü—Ä–∏–≤–µ—Ç!!!"
#s = input() # –ï—Å–ª–∏ –Ω—É–∂–Ω–æ –≤–≤–æ–¥–∏—Ç—å —á–µ—Ä–µ–∑ —Ç–µ—Ä–º–∏–Ω–∞–ª
top = 5
a = text.normalize(s, casefold=True, yo2e=True) # –§–æ—Ä–º–∞—Ç–∏—Ä—É–µ–º —Ç–µ–∫—Å—Ç
a = text.tokenize(a) # –£–±–∏—Ä–∞–µ–º –ª–∏—à–Ω–∏–µ —Å–∏–º–≤–æ–ª—ã
a = text.count_freq(a) # –§–æ—Ä–º–∏—Ä—É–µ–º —Å–ª–æ–≤–∞—Ä—å
print(f"–í—Å–µ–≥–æ —Å–ª–æ–≤: {len(s.split())}")
print(f"–£–Ω–∏–∫–∞–ª—å–Ω—ã—Ö —Å–ª–æ–≤: {len(a)}")
a = text.top_n(a, 5) # –§–æ—Ä–º–∏—Ä—É–µ–º –¢–æ–ø
print('–¢–æ–ø-5:')
for x, y in a: # –í—ã–≤–æ–¥–∏–º –¢–æ–ø
    print(f"{x}: {y}")
```
–°–∫—Ä–∏–Ω—à–æ—Ç –∑–∞–¥–∞–Ω–∏—è B
![04](https://github.com/2BOCXOD2/python_labs/blob/main/img/lab03/2.1.PNG)
## **–ó–∞–¥–∞–Ω–∏–µ –ë**
### –ö–æ–¥ –∑–∞–¥–∞–Ω–∏—è –ë
```
import sys
import os
sys.path.insert(0, os.path.join(sys.path[0], '../lib')) # –î–æ–±–∞–≤–∏–ª–∏ –ø—É—Ç—å –≤ –ø–∞–ø–∫—É —Å —Ñ—É–Ω–∫—Ü–∏—è–º–∏
import text # normalize, tokenize, count_freq, top_n

s = "–ü—Ä–∏–≤–µ—Ç, –º–∏—Ä! –ü—Ä–∏–≤–µ—Ç!!!"
#s = input() # –ï—Å–ª–∏ –Ω—É–∂–Ω–æ –≤–≤–æ–¥–∏—Ç—å —á–µ—Ä–µ–∑ —Ç–µ—Ä–º–∏–Ω–∞–ª
top = 5
a = text.normalize(s, casefold=True, yo2e=True) # –§–æ—Ä–º–∞—Ç–∏—Ä—É–µ–º —Ç–µ–∫—Å—Ç
a = text.tokenize(a) # –£–±–∏—Ä–∞–µ–º –ª–∏—à–Ω–∏–µ —Å–∏–º–≤–æ–ª—ã
a = text.count_freq(a) # –§–æ—Ä–º–∏—Ä—É–µ–º —Å–ª–æ–≤–∞—Ä—å
print(f"–í—Å–µ–≥–æ —Å–ª–æ–≤: {len(s.split())}")
print(f"–£–Ω–∏–∫–∞–ª—å–Ω—ã—Ö —Å–ª–æ–≤: {len(a)}")
a = text.top_n(a, 5) # –§–æ—Ä–º–∏—Ä—É–µ–º –¢–æ–ø
print('–¢–æ–ø-5:')
print("______________________") # –í—ã–≤–æ–¥–∏–º –¥–∞–Ω–Ω—ã–µ –∫—Ä–∞—Å–∏–≤–æ
max_len = 5 # –ú–∏–Ω–∏–º–∞–ª—å–Ω–∞—è —à–∏—Ä–∏–Ω–∞ —Å—Ç–æ–ª–±—Ü–∞ "–°–ª–æ–≤–æ"
for r, t in a: # –ü–æ–∏—Å–∫ –º–∞–∫—Å–∏–º–∞–ª—å–Ω–æ–π –¥–ª–∏–Ω—ã —Å–ª–æ–≤–∞
    max_len = max(max_len, len(r))
print(f"–°–ª–æ–≤–æ{" " * (max_len - 4)}| –ß–∞—Å—Ç–æ—Ç–∞") # –ö—Ä–∞—Å–∏–≤–æ –≤—ã–≤–æ–¥–∏–º —Å–ª–æ–≤–æ –∏ —á–∞—Å—Ç–æ—Ç—É —Ä–æ–≤–Ω—ã–º–∏ —Å—Ç–æ–ª–±—Ü–∞–º–∏
print("----------------------")
for x, y in a: # –í—ã–≤–æ–¥–∏–º –¢–æ–ø –∫—Ä–∞—Å–∏–≤–æ
    print(f"{x}{" " * (max_len - len(x) + 1)}| {y}") #–ö—Ä–∞—Å–∏–≤–æ –≤—ã–≤–æ–¥–∏–º —Å–ª–æ–≤–æ –∏ —á–∞—Å—Ç–æ—Ç—É —Ä–æ–≤–Ω—ã–º–∏ —Å—Ç–æ–ª–±—Ü–∞–º–∏
```
![05](https://github.com/2BOCXOD2/python_labs/blob/main/img/lab03/2.2.PNG)